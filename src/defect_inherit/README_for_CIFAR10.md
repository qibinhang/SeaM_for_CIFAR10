## Introduce
To match the Q4's index of Huawei Project, experiments on CIFAR-10 have been added, involving the following files: `standard_finetune_cifar10.py`, `modular_finetune_cifar10.py`, and `eval_robustness_cifar10.py`.

ResNet18 pre-trained on ImageNet is fine-tuned on CIFAR-10 through standard fine-tuning and SeaM.
The resulting fine-tuned models are evaluated in terms of adversarial attacks.

The results show that the fine-tuned model generated by SeaM is more robust than that generated by standard fine-tuning (2.82% vs 19.1% in DIRs). So, SeaM can improve the accuracy in target classes (i.e., the classes of the target problem).

## To reproduce results mentioned above, one can follow the instructions below:
```
cd ./src/defect_inherit
python -u eval_robustness_cifar10.py --model resnet18  --eval_method standard
python -u eval_robustness_cifar10.py --model resnet18  --eval_method seam --lr_mask 0.05 --alpha 0.5 
```

## One can also fine-tune the model again through standard fine-tuning method and SeaM:
```
cd ./src/defect_inherit
python -u standard_finetune_cifar10.py
python -u modular_finetune_cifar10.py --model resnet18 --alpha 0.5 --lr_s2_mask 0.05 
```

